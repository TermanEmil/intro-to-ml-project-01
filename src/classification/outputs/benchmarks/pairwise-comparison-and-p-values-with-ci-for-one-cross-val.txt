C:\Users\terma\AppData\Local\Programs\Python\Python38\python.exe C:\Users\terma\Projects\dtu\intro-to-ml\project\src\classification\benchmarking.py

 ==================== Run 1/1 ====================
---------- fold: 1/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.6124089       5.5863256e-05
                2000    0.59147316      2.82157e-05
                3000    0.57141644      1.7106604e-05
                Final loss:
                3000    0.57141644      1.7106604e-05

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.6163827       7.4647374e-05
                2000    0.5866431       3.393422e-05
                3000    0.5734396       1.5695045e-05
                Final loss:
                3000    0.5734396       1.5695045e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.6205551       7.0976304e-05
                2000    0.5924342       4.0443472e-05
                3000    0.57576406      1.7805585e-05
                Final loss:
                3000    0.57576406      1.7805585e-05
---------- fold: 2/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.6225549       5.7346162e-05
                2000    0.6001771       2.264257e-05
                3000    0.5906863       1.1604221e-05
                Final loss:
                3000    0.5906863       1.1604221e-05

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.6102392       7.2762006e-05
                2000    0.581893        2.4685576e-05
                3000    0.57211524      1.2085075e-05
                Final loss:
                3000    0.57211524      1.2085075e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.6045559       5.668744e-05
                2000    0.58356744      2.3593413e-05
                3000    0.57468414      8.297309e-06
                Final loss:
                3000    0.57468414      8.297309e-06
---------- fold: 3/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.61056846      4.675854e-05
                2000    0.5942466       1.5747304e-05
                3000    0.58765626      7.911301e-06
                Final loss:
                3000    0.58765626      7.911301e-06

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.60341954      4.997923e-05
                2000    0.5868639       1.5336032e-05
                3000    0.5753826       1.3881045e-05
                Final loss:
                3000    0.5753826       1.3881045e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.6070981       5.5959237e-05
                2000    0.58317536      2.9128167e-05
                3000    0.57011884      1.1813757e-05
                Final loss:
                3000    0.57011884      1.1813757e-05
---------- fold: 4/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.6142984       6.345282e-05
                2000    0.5909373       2.4106053e-05
                3000    0.57689846      1.2294825e-05
                Final loss:
                3000    0.57689846      1.2294825e-05

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.6246904       7.642133e-05
                2000    0.59816134      2.7900223e-05
                3000    0.58203167      2.9902214e-05
                Final loss:
                3000    0.58203167      2.9902214e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.6099335       5.6676236e-05
                2000    0.59025717      2.534554e-05
                3000    0.5761109       1.1380511e-05
                Final loss:
                3000    0.5761109       1.1380511e-05
---------- fold: 5/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.60793537      4.372588e-05
                2000    0.5863923       3.8827406e-05
                3000    0.5723614       1.6661823e-05
                Final loss:
                3000    0.5723614       1.6661823e-05

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.6170841       7.340362e-05
                2000    0.59046376      2.8869572e-05
                3000    0.57666147      2.739007e-05
                Final loss:
                3000    0.57666147      2.739007e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.6206448       5.92511e-05
                2000    0.5980914       2.4515288e-05
                3000    0.5844741       4.6908583e-05
                Final loss:
                3000    0.5844741       4.6908583e-05
---------- fold: 6/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.60352796      4.6020214e-05
                2000    0.583827        3.9508424e-05
                3000    0.5732986       9.3570225e-06
                Final loss:
                3000    0.5732986       9.3570225e-06

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.60332084      4.988862e-05
                2000    0.5844574       2.39654e-05
                3000    0.5745451       1.6079803e-05
                Final loss:
                3000    0.5745451       1.6079803e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.6141989       8.06375e-05
                2000    0.58859956      2.7442113e-05
                3000    0.5780724       1.1238788e-05
                Final loss:
                3000    0.5780724       1.1238788e-05
---------- fold: 7/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.6126855       5.1752537e-05
                2000    0.59230375      2.415107e-05
                3000    0.5771319       1.9415762e-05
                Final loss:
                3000    0.5771319       1.9415762e-05

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.6073103       4.3378335e-05
                2000    0.5879378       2.5141402e-05
                3000    0.578224        9.895801e-06
                Final loss:
                3000    0.578224        9.895801e-06

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.6037983       4.31371e-05
                2000    0.5798225       5.859148e-05
                3000    0.5659473       1.042641e-05
                Final loss:
                3000    0.5659473       1.042641e-05
---------- fold: 8/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.6019874       5.6335284e-05
                2000    0.5845917       1.508977e-05
                3000    0.57903534      5.8674223e-06
                Final loss:
                3000    0.57903534      5.8674223e-06

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.6019205       5.168792e-05
                2000    0.58410186      1.6939175e-05
                3000    0.57038707      1.3062153e-05
                Final loss:
                3000    0.57038707      1.3062153e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.6163229       5.9956667e-05
                2000    0.5931631       2.5522819e-05
                3000    0.57981503      1.603645e-05
                Final loss:
                3000    0.57981503      1.603645e-05
---------- fold: 9/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.59793884      4.814482e-05
                2000    0.579736        1.8300456e-05
                3000    0.57237613      7.8100975e-06
                Final loss:
                3000    0.57237613      7.8100975e-06

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.5946594       4.8310092e-05
                2000    0.57785946      2.5579877e-05
                3000    0.5692921       1.0679243e-05
                Final loss:
                3000    0.5692921       1.0679243e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.5875212       4.747684e-05
                2000    0.57390076      1.3501462e-05
                3000    0.56773025      8.083981e-06
                Final loss:
                3000    0.56773025      8.083981e-06
---------- fold: 10/10 ----------

        Replicate: 1/3
                Iter    Loss                    Rel. loss
                1000    0.6157612       5.1010105e-05
                2000    0.5917862       4.461692e-05
                3000    0.5762064       1.5930002e-05
                Final loss:
                3000    0.5762064       1.5930002e-05

        Replicate: 2/3
                Iter    Loss                    Rel. loss
                1000    0.61113095      4.9738697e-05
                2000    0.5816419       3.6070436e-05
                3000    0.5651153       3.680887e-05
                Final loss:
                3000    0.5651153       3.680887e-05

        Replicate: 3/3
                Iter    Loss                    Rel. loss
                1000    0.61540914      5.5203556e-05
                2000    0.5943125       2.9284336e-05
                3000    0.58193994      1.3622213e-05
                Final loss:
                3000    0.58193994      1.3622213e-05
A total of 210 predictions
Coefficients for the first logistic regression
+----+-------------------+------------------------------+
|    | features          | coefficients                 |
|----+-------------------+------------------------------|
|  0 | area              | [ 1.7862  5.7328 -7.519 ]    |
|  1 | perimeter         | [-3.0689  5.5012 -2.4323]    |
|  2 | compactness       | [ 1.8448 -0.844  -1.0008]    |
|  3 | kernel len        | [11.9869 -9.0594 -2.9275]    |
|  4 | kernel width      | [-4.2785  0.7056  3.573 ]    |
|  5 | asymmetry         | [-2.3125  2.0707  0.2418]    |
|  6 | kernel groove len | [-10.4538   6.9107   3.5431] |
+----+-------------------+------------------------------+
Mean of the absolute values of the coefficients for logistic regression
+----+-------------------+---------------------------+
|    | features          | coefficients              |
|----+-------------------+---------------------------|
|  0 | area              | [1.7186 5.6025 7.3211]    |
|  1 | perimeter         | [2.4302 5.4577 3.154 ]    |
|  2 | compactness       | [1.6303 1.0345 0.8637]    |
|  3 | kernel len        | [11.0564  8.7452  2.3112] |
|  4 | kernel width      | [3.8709 1.1828 3.1335]    |
|  5 | asymmetry         | [2.2876 1.901  0.3867]    |
|  6 | kernel groove len | [10.0227  6.5632  3.4595] |
+----+-------------------+---------------------------+
Mean of the coefficients for logistic regression
+----+-------------------+------------------------------+
|    | features          | coefficients                 |
|----+-------------------+------------------------------|
|  0 | area              | [ 1.7186  5.6025 -7.3211]    |
|  1 | perimeter         | [-2.3038  5.4577 -3.154 ]    |
|  2 | compactness       | [ 1.6209 -1.0345 -0.5865]    |
|  3 | kernel len        | [11.0564 -8.7452 -2.3112]    |
|  4 | kernel width      | [-3.8709  1.1245  2.7464]    |
|  5 | asymmetry         | [-2.2876  1.901   0.3867]    |
|  6 | kernel groove len | [-10.0227   6.5632   3.4595] |
+----+-------------------+------------------------------+

 ==================== Logistic vs ANN
McNemar
Result of McNemars test using alpha= 0.05
Comparison matrix n
[[196.   4.]
 [  3.   7.]]
Warning, n12+n21 is low: n12+n21= 7.0
Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (-0.019864961607890086, 0.029385922449554736)
p-value for two-sided test A and B have same accuracy (exact binomial test): p= 1.0
theta = 0.004761904761904762; CI: (-0.019864961607890086, 0.029385922449554736); p-value: 1.0

Setup II
p_setupII = 0.7629432013913908; CI_setupII = (-0.03940822100202911, 0.029884411478219592)

 ==================== Logistic vs Baseline
McNemar
Result of McNemars test using alpha= 0.05
Comparison matrix n
[[ 36. 164.]
 [  4.   6.]]
Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (0.695213114311398, 0.8214266308972369)
p-value for two-sided test A and B have same accuracy (exact binomial test): p= 1.7538320135283241e-43
theta = 0.7619047619047619; CI: (0.695213114311398, 0.8214266308972369); p-value: 1.7538320135283241e-43

Setup II
p_setupII = 8.669739368003586e-09; CI_setupII = (-0.8476321619376105, -0.676177361871913)

 ==================== ANN vs Baseline
McNemar
Result of McNemars test using alpha= 0.05
Comparison matrix n
[[ 35. 164.]
 [  5.   6.]]
Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (0.6886426327320931, 0.818255457855122)
p-value for two-sided test A and B have same accuracy (exact binomial test): p= 2.982374818031506e-42
theta = 0.7571428571428571; CI: (0.6886426327320931, 0.818255457855122); p-value: 2.982374818031506e-42

Setup II
p_setupII = 4.022989298568026e-09; CI_setupII = (-0.8352442355340572, -0.679041478751657)
